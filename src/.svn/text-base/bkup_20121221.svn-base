//============================================================================
// Name        : Empty.cpp
// Author      :
// Version     :
// Copyright   : Your copyright notice
// Description : Hello World in C++, Ansi-style
//============================================================================
#include <iostream>
#include <cv.h>
#include <highgui.h>
#include <stdio.h>
#include <stdlib.h>
#include <string.h>
#include <assert.h>
#include "libfreenect.h"
#include "libfreenect_sync.h"
#include <pthread.h>
#include <GL/glut.h>
#include <GL/gl.h>
#include <GL/glu.h>
#include <math.h>
#include <pthread.h>
#include <math.h>
#include <alsa/asoundlib.h>
#include "portaudio.h"

#include "/root/workspace/include-files/cvideo.h"
#include "/root/workspace/include-files/load_image.h"
#include "/root/workspace/include-files/utility.h"
#include "/root/workspace/include-files/viewer.h"
#include "/root/workspace/include-files/TCPServerSocket.h"
#include "/root/workspace/include-files/TCPClientSocket.h"
#include "/root/workspace/include-files/image_processing.h"
#include "/root/workspace/include-files/camera.h"

#define numOfCamera 1
bool proximityViewEnabled=false;
utility util;
TCPClientSocket client1;
cvideo encoder;

using namespace std;

char *depth_mid, *depth_front;
char *rgb_back, *rgb_mid, *rgb_front;
char *backgroudnImage_mean;

int gwidth=640;
int gheight=480;
int got_depth = 0;
char t_gamma[2048];

int freenect_led;
freenect_context *f_ctx;
freenect_device *f_dev;
freenect_video_format requested_format = FREENECT_VIDEO_RGB;
freenect_video_format current_format = FREENECT_VIDEO_RGB;
freenect_resolution requested_resolution = FREENECT_RESOLUTION_MEDIUM;
freenect_resolution current_resolution = FREENECT_RESOLUTION_MEDIUM;
pthread_mutex_t depth_mutex = PTHREAD_MUTEX_INITIALIZER;
pthread_mutex_t video_mutex = PTHREAD_MUTEX_INITIALIZER;

/* #define SAMPLE_RATE  (17932) // Test failure to open with this value. */
#define SAMPLE_RATE  (44100)
#define FRAMES_PER_BUFFER (128)
#define NUM_SECONDS     (0.01)
#define NUM_CHANNELS    (2)
/* #define DITHER_FLAG     (paDitherOff) */
#define DITHER_FLAG     (0) /**/
/** Set to 1 if you want to capture the recording to a file. */
#define WRITE_TO_FILE   (0)

/* Select sample format. */
#define PA_SAMPLE_TYPE  paFloat32
typedef float SAMPLE;
#define SAMPLE_SILENCE  (0.0f)
#define PRINTF_S_FORMAT "%.8f"

typedef struct
{
	int          frameIndex;  /* Index into sample array. */
	int          maxFrameIndex;
	SAMPLE      *recordedSamples;
}
paTestData;



static int recordCallback( const void *inputBuffer, void *outputBuffer,
		unsigned long framesPerBuffer,
		const PaStreamCallbackTimeInfo* timeInfo,
		PaStreamCallbackFlags statusFlags,
		void *userData )
{
	paTestData *data = (paTestData*)userData;
	const SAMPLE *rptr = (const SAMPLE*)inputBuffer;
	SAMPLE *wptr = &data->recordedSamples[data->frameIndex * NUM_CHANNELS];
	long framesToCalc;
	long i;
	int finished;
	unsigned long framesLeft = data->maxFrameIndex - data->frameIndex;

	(void) outputBuffer; /* Prevent unused variable warnings. */
	(void) timeInfo;
	(void) statusFlags;
	(void) userData;

	if( framesLeft < framesPerBuffer )
	{
		framesToCalc = framesLeft;
		finished = paComplete;
	}
	else
	{
		framesToCalc = framesPerBuffer;
		finished = paContinue;
	}

	if( inputBuffer == NULL )
	{
		for( i=0; i<framesToCalc; i++ )
		{
			*wptr++ = SAMPLE_SILENCE;  /* left */
			if( NUM_CHANNELS == 2 ) {
				*wptr++ = SAMPLE_SILENCE;  /* right */
			}
		}
	}
	else
	{
		for( i=0; i<framesToCalc; i++ )
		{
			*wptr++ = *rptr++;  /* left */
			if( NUM_CHANNELS == 2 ){
				*wptr++ = *rptr++;  /* right */
			}
		}
	}
	data->frameIndex += framesToCalc;
	SAMPLE val = data->recordedSamples[data->frameIndex];
	//    printf("-----%d  %d  %f\n",data->frameIndex, framesToCalc, val);
	return finished;
}

static int playCallback( const void *inputBuffer, void *outputBuffer,
		unsigned long framesPerBuffer,
		const PaStreamCallbackTimeInfo* timeInfo,
		PaStreamCallbackFlags statusFlags,
		void *userData )
{
	paTestData *data = (paTestData*)userData;
	SAMPLE *rptr = &data->recordedSamples[data->frameIndex * NUM_CHANNELS];
	SAMPLE *wptr = (SAMPLE*)outputBuffer;
	unsigned int i;
	int finished;
	unsigned int framesLeft = data->maxFrameIndex - data->frameIndex;

	(void) inputBuffer; /* Prevent unused variable warnings. */
	(void) timeInfo;
	(void) statusFlags;
	(void) userData;

	if( framesLeft < framesPerBuffer )
	{
		/* final buffer... */
		for( i=0; i<framesLeft; i++ )
		{
			*wptr++ = *rptr++;  /* left */
			if( NUM_CHANNELS == 2 ) *wptr++ = *rptr++;  /* right */
		}
		for( ; i<framesPerBuffer; i++ )
		{
			*wptr++ = 0;  /* left */
			if( NUM_CHANNELS == 2 ) *wptr++ = 0;  /* right */
		}
		data->frameIndex += framesLeft;
		finished = paComplete;
	}
	else
	{
		for( i=0; i<framesPerBuffer; i++ )
		{
			*wptr++ = *rptr++;  /* left */
			if( NUM_CHANNELS == 2 ) *wptr++ = *rptr++;  /* right */
		}
		data->frameIndex += framesPerBuffer;
		finished = paContinue;
	}
	return finished;
}

void storeDispVal_ext(Camera* data, int* returnVal)
{
	int widthIndex=0;
	int heightIndex=0;
	double valToSave=0;
	for(int k=0;k<data->height*data->width;k++)
	{
		//						printf("%f\n",0.1236 * tan((double)data[0].rawdepthImage[i]/ 2842.5 + 1.1863));
		double raw_depth=(double)data->rawdepthImage[k];

		if (raw_depth < 2047)
		{
			//					fprintf(pFile,"%f,",(1.0 / (raw_depth * -0.0030711016 + 3.3309495161))*10);
			//			printf("%f,",(1.0 / (raw_depth * -0.0030711016 + 3.3309495161))*10);
			valToSave=(1.0 / (raw_depth * -0.0030711016 + 3.3309495161))*10;
			returnVal[k]=(int)valToSave;
		}
		else
		{
			raw_depth=0;
			valToSave=(1.0 / (raw_depth * -0.0030711016 + 3.3309495161))*10;
			returnVal[k]=(int)valToSave;
		}

		if(k%data->width==0 && k!=0)
		{
			//					fprintf(pFile,"\n");
			//			printf("\n");
			heightIndex++;
		}
	}
}
void depth_cb(freenect_device *dev, void *v_depth, uint32_t timestamp)
{
	int i;
	uint16_t *depth = (uint16_t*)v_depth;

	pthread_mutex_lock(&depth_mutex);
	for (i=0; i<640*480; i++) {
		int pval = t_gamma[depth[i]];
		int lb = pval & 0xff;
		switch (pval>>8) {
		case 0:
			depth_mid[3*i+0] = 255;
			depth_mid[3*i+1] = 255-lb;
			depth_mid[3*i+2] = 255-lb;
			break;
		case 1:
			depth_mid[3*i+0] = 255;
			depth_mid[3*i+1] = lb;
			depth_mid[3*i+2] = 0;
			break;
		case 2:
			depth_mid[3*i+0] = 255-lb;
			depth_mid[3*i+1] = 255;
			depth_mid[3*i+2] = 0;
			break;
		case 3:
			depth_mid[3*i+0] = 0;
			depth_mid[3*i+1] = 255;
			depth_mid[3*i+2] = lb;
			break;
		case 4:
			depth_mid[3*i+0] = 0;
			depth_mid[3*i+1] = 255-lb;
			depth_mid[3*i+2] = 255;
			break;
		case 5:
			depth_mid[3*i+0] = 0;
			depth_mid[3*i+1] = 0;
			depth_mid[3*i+2] = 255-lb;
			break;
		default:
			depth_mid[3*i+0] = 0;
			depth_mid[3*i+1] = 0;
			depth_mid[3*i+2] = 0;
			break;
		}
	}
	got_depth++;
	pthread_mutex_unlock(&depth_mutex);
}

short* grabKinectDepthImage(Camera data)
{
	short *depth = 0;
	uint32_t ts;
	if (freenect_sync_get_depth((void**)&depth, &ts, data.cameraIndex, FREENECT_DEPTH_11BIT) < 0)
	{
		printf("Kinect is not connected\n");
		exit(1);
	}
	return depth;
}

char* grabDepthImageChar(int deviceIndex)
{
	char *depth = 0;
	uint32_t ts;
	if (freenect_sync_get_depth((void**)&depth, &ts, deviceIndex, FREENECT_DEPTH_11BIT) < 0)
	{
		printf("Kinect is not connected\n");
		exit(1);
	}
	return depth;
}


char* grabKinectRGBImage(int deviceIndex){
	char* returnImage=0;
	uint32_t ts;
	if(freenect_sync_get_video((void**)&returnImage, &ts, deviceIndex, 	FREENECT_VIDEO_RGB )<0)
	{
		printf("Kinect is not connected\n");
		exit(1);
	}
	//	save_ppm("/home/sklee25/Desktop/kinect_depth.ppm",returnImage,640,480);
	//	getchar();
	return returnImage;
}

char* grabKinectVisibleImage(Camera data)
{
	char* returnImage=0;
	uint32_t ts;
	if(freenect_sync_get_video((void**)&returnImage, &ts, data.cameraIndex, FREENECT_VIDEO_RGB)<0)
	{
		printf("Kinect is not connected\n");
		exit(1);
	}

	convertToGrayScale(returnImage, data.rawgrayImage, gwidth,gheight);
	return returnImage;

}

void grabKinectGrayImage(Camera data){
	uint32_t ts;
	if(freenect_sync_get_video((void**)&data.rawrgbImage, &ts, data.cameraIndex, FREENECT_VIDEO_RGB)<0)
	{
		printf("Kinect is not connected\n");
		exit(1);
	}

	convertToGrayScale(data.rawrgbImage, data.rawgrayImage, gwidth,gheight);
}

void grabKinectBackgroundGrayImage(Camera data){
	uint32_t ts;
	if(freenect_sync_get_video((void**)&data.rawrgbImage, &ts, data.cameraIndex, FREENECT_VIDEO_RGB)<0)
	{
		printf("Kinect is not connected\n");
		exit(1);
	}

	convertToGrayScale(data.rawrgbImage, data.backgroundImage, gwidth,gheight);
}

void initKinect()
{
	if (freenect_init(&f_ctx, NULL) < 0) {
		printf("freenect_init() failed\n");
	}
	freenect_set_log_level(f_ctx, FREENECT_LOG_DEBUG);
	freenect_select_subdevices(f_ctx, (freenect_device_flags)(FREENECT_DEVICE_MOTOR | FREENECT_DEVICE_CAMERA));

	int nr_devices = freenect_num_devices (f_ctx);
	printf ("Number of devices found: %d\n", nr_devices);
}





double getSound()
{
	PaStreamParameters  inputParameters,outputParameters;
	PaStream*           stream;
	PaError             err = paNoError;
	paTestData          data;
	int                 i;
	int                 totalFrames;
	int                 numSamples;
	int                 numBytes;
	SAMPLE              max, val;
	double              average;

	data.maxFrameIndex = totalFrames = NUM_SECONDS * SAMPLE_RATE; /* Record for a few seconds. */
	data.maxFrameIndex = totalFrames = 1;

	data.frameIndex = 0;
	numSamples = totalFrames * NUM_CHANNELS;
	numBytes = numSamples * sizeof(SAMPLE);
	data.recordedSamples = (SAMPLE *) malloc( numBytes ); /* From now on, recordedSamples is initialised. */
	if( data.recordedSamples == NULL )
	{
		printf("Could not allocate record array.\n");
		//		goto done;
	}
	for( i=0; i<numSamples; i++ ) data.recordedSamples[i] = 0;

	err = Pa_Initialize();
	//	if( err != paNoError ) goto done;

	inputParameters.device = Pa_GetDefaultInputDevice(); /* default input device */
	if (inputParameters.device == paNoDevice) {
		fprintf(stderr,"Error: No default input device.\n");
		//		goto done;
	}
	inputParameters.channelCount = 2;                    /* stereo input */
	inputParameters.sampleFormat = PA_SAMPLE_TYPE;
	inputParameters.suggestedLatency = Pa_GetDeviceInfo( inputParameters.device )->defaultLowInputLatency;
	inputParameters.hostApiSpecificStreamInfo = NULL;

	/* Record some audio. -------------------------------------------- */
	err = Pa_OpenStream(
			&stream,
			&inputParameters,
			NULL,                  /* &outputParameters, */
			SAMPLE_RATE,
			FRAMES_PER_BUFFER,
			paClipOff,      /* we won't output out of range samples so don't bother clipping them */
			recordCallback,
			&data );
	//	if( err != paNoError ) goto done;

	err = Pa_StartStream( stream );
	//	if( err != paNoError ) goto done;
	//	printf("\n=== Now recording!! Please speak into the microphone. ===\n"); fflush(stdout);

	while( ( err = Pa_IsStreamActive( stream ) ) == 1 )
	{
		//		Pa_Sleep(1);
		//		printf("index = %d\n", data.frameIndex );
		//		fflush(stdout);
	}
	//	if( err < 0 ) goto done;
	err = Pa_CloseStream( stream );
	//	if( err != paNoError ) goto done;

	/* Measure maximum peak amplitude. */
	max = 0;
	average = 0.0;
	for( i=0; i<numSamples; i++ )
	{
		val = data.recordedSamples[i];
		//        printf("%f\n",val);
		if( val < 0 ) val = -val; /* ABS */
		if( val > max )
		{
			max = val;
		}
		average += val;
	}
	average = average / (double)numSamples;
	//	printf("%f\n",average);
	return average;

	//	printf("sample max amplitude = "PRINTF_S_FORMAT"\n", max );
	//	printf("sample average = %lf\n", average );

	/* Playback recorded data.  -------------------------------------------- */
	//	done:
	//	Pa_Terminate();
	//	if( data.recordedSamples )       /* Sure it is NULL or valid. */
	//		free( data.recordedSamples );
	//	if( err != paNoError )
	//	{
	//		fprintf( stderr, "An error occured while using the portaudio stream\n" );
	//		fprintf( stderr, "Error number: %d\n", err );
	//		fprintf( stderr, "Error message: %s\n", Pa_GetErrorText( err ) );
	//		err = 1;          /* Always return 0 or 1, but no other return codes. */
	//	}
	//    return err;
}

int main(int argc, char **argv) {
	int NumOfGrabbedImages=0;
	initKinect();
	Camera data[numOfCamera];//=new Camera[numOfCamera];


	for(int i=0;i<numOfCamera;i++)
	{
		data[i]=Camera(i);
	}

	//	double prevSound;
	//	double currentSound;
	//	double difference=0.0;
	//	double firstSound=0.0;
	int depthCounter=0;
	for(int i=0;i<numOfCamera;i++)
	{
		grabKinectBackgroundGrayImage(data[i]);
		data[i].grayImage=convertCharGrayArrayToIplImage(data[0].backgroundImage,data[0].height,data[0].width);
	}

	cvShowImage("background", data[0].grayImage);
	char* rgbWindowName=new char[100];
	printf("Acquired Background Image\n");
	getchar();

	while(1)
	{
		//		double soundVal=getSound();
		//		soundVal=soundVal*1000-45;
		//		prevSound=soundVal*1000-45;
		//		getchar();
		for(int i=0;i<numOfCamera;i++)
		{
			data[i].rawrgbImage=grabKinectVisibleImage(data[i]);
			data[i].rawdepthImage=grabKinectDepthImage(data[i]);

			for(int k=0;k<data[i].height*data[i].width;k++)
			{
				int pixelForegroundDepth=(uint8_t)data[i].rawgrayImage[k];//-data[i].rawdepthImage[k];
				int pixelBackgroundDepth=(uint8_t)data[i].backgroundImage[k];
				int pixel=pixelForegroundDepth-pixelBackgroundDepth;

				if(pixel<50)
				{
					pixel=0;
					data[i].dataWithDepth[k]=(short)0;
				}
				if(pixel>255)
				{
					pixel=255;
				}
				if(pixel!=0)
				{
					data[i].dataWithDepth[k]=data[i].rawdepthImage[k];
					data[i].autoViewVal=data[i].autoViewVal+(int)data[i].dataWithDepth[k];
					depthCounter++;
				}
			}
			data[i].autoViewVal=data[i].autoViewVal/depthCounter;
			printf("%d\n",data[i].autoViewVal);


			///////////////////////////////////////////////////////////////////
			int sendArraySize=(data[i].width*data[i].height*3+1);
			char* sendBuffer=(char*)malloc(sizeof(char)*sendArraySize);
			memcpy(sendBuffer,data[i].rawrgbImage,sendArraySize);


			char sendVal=(uint8_t)data[i].autoViewVal;
			memcpy(&sendBuffer[sendArraySize-1],&sendVal,sizeof(char));

			client1.EstablishConnection("163.152.21.249",6000);

			client1.SendData(client1.sock, sendBuffer, sendArraySize);
			delete[] sendBuffer;
			///////////////////////////////////////////////////////////////////


			data[i].depthImage=convertShortGrayArrayToIplImage(data[i].dataWithDepth,data[i].height,data[i].width);
			sprintf(rgbWindowName,"image_image%d",i);
			cvShowImage(rgbWindowName, data[i].depthImage);
		}

		if(proximityViewEnabled==true)
		{
			if(data[1].autoViewVal>data[0].autoViewVal)
			{
				data[1].rgbImage=convertColorArrayToIplImage(data[1].rawrgbImage,data[1].height,data[1].width);
				cvShowImage("main_display", data[1].rgbImage);
			}
			else
			{
				data[0].rgbImage=convertColorArrayToIplImage(data[0].rawrgbImage,data[0].height,data[0].width);
				cvShowImage("main_display", data[0].rgbImage);
			}
		}
		cvWaitKey(2);

		for(int i=0;i<numOfCamera;i++)
		{
			data[i].cleanImageMemory();
		}

	}
	printf("Done with sound()\n");

	return 0;
}
